{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CREDIT NEWSAPI!!!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install paramiko"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#News API doc: https://newsapi.org/docs/endpoints/everything\n",
    "#Sentiment lexicon http://mpqa.cs.pitt.edu/lexicons/subj_lexicon/\n",
    "#from https://towardsdatascience.com/introduction-to-natural-language-processing-for-text-df845750fb63\n",
    "# Import the libraries we need\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scrape wiki article for cabinet members\n",
    "base_url='https://en.wikipedia.org/wiki/Cabinet_of_the_United_States'\n",
    "req=requests.get(base_url)\n",
    "cab_soup = BeautifulSoup(req.content, 'html.parser')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create list of cabinet members\n",
    "cabinet = [cab_soup.find_all('table')[3].find_all('tr')[i].find_all('td')[1].find_all('a')[-1]['title']\n",
    " for i in range(1,len(cab_soup.find_all('table')[3].find_all('tr')))\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "#president\n",
    "president = ['Donald Trump']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrape wiki article for senators\n",
    "base_url='https://en.wikipedia.org/wiki/List_of_current_United_States_Senators'\n",
    "req=requests.get(base_url)\n",
    "sen_soup = BeautifulSoup(req.content, 'html.parser')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create list of senators\n",
    "senate=[sen_soup.find_all('table')[4].tbody.find_all('tr')[i].find_all('th')[0].find_all('a')[0]['title']\n",
    " for i in range(1,len(sen_soup.find_all('table')[4].find_all('tr')))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrape wiki for congresspeople\n",
    "base_url='https://en.wikipedia.org/wiki/List_of_current_members_of_the_United_States_House_of_Representatives'\n",
    "req=requests.get(base_url)\n",
    "house_soup = BeautifulSoup(req.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create list of congresspeople\n",
    "house=[house_soup.find_all('table')[6].find_all('tr')[i].find_all('td')[1].find_all('a')[-1]['title']\n",
    " for i in range(1,len(house_soup.find_all('table')[6].find_all('tr')))\n",
    " if len(house_soup.find_all('table')[6].find_all('tr')[i].find_all('td')[1].find_all('i'))==0\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "#democratic candidates\n",
    "demcands = [\"Beto O'Rourke\",'Pete Buttigieg','Julian Castro','Jay Inslee']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concatenate political lists\n",
    "politicians = [re.sub(\" \\(.*?\\)\",\"\",name) for name in cabinet+senate+house+demcands]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run queries for non-trump politicians\n",
    "date = '2019-08-05'\n",
    "for i in range(int(len(politicians)/100)+1):\n",
    "    qlist = politicians[i*100:(i+1)*100]\n",
    "    base_url = \"https://newsapi.org/v2/everything\"\n",
    "    req= requests.get(\n",
    "    base_url,\n",
    "    params={'q':qlist,\n",
    "       'from':date,\n",
    "       'sortBy':'popularity',\n",
    "        'pageSize':100,\n",
    "        'page':1,\n",
    "       'language':'en',\n",
    "       'apiKey':'697e87dceab84ce18c49963b7da44ac3'})\n",
    "    filename = './data/newscrape'+date+str(i)+'.csv'\n",
    "    if 'articles' in req.json().keys():\n",
    "        pd.DataFrame(req.json(),index=range(len(req.json()['articles']))).to_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run queries for trump\n",
    "date = '2019-08-10'\n",
    "qlist = president\n",
    "base_url = \"https://newsapi.org/v2/everything\"\n",
    "req= requests.get(\n",
    "base_url,\n",
    "params={'q':qlist,\n",
    "   'from':date,\n",
    "   'sortBy':'popularity',\n",
    "    'pageSize':100,\n",
    "    'page':1,\n",
    "    'language':'en',\n",
    "   'apiKey':'697e87dceab84ce18c49963b7da44ac3'})\n",
    "filename = './data/newscrape'+date+'trump'+'.csv'\n",
    "if 'articles' in req.json().keys():\n",
    "    pd.DataFrame(req.json(),index=range(len(req.json()['articles']))).to_csv(filename)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_news(date,politicians):\n",
    "    n_articles=0\n",
    "    president = \"Donald Trump\"\n",
    "    base_url = \"https://newsapi.org/v2/everything\"\n",
    "    for i in range(int(len(politicians)/100)+1):\n",
    "        qlist = politicians[i*100:(i+1)*100]\n",
    "        req= requests.get(\n",
    "        base_url,\n",
    "        params={'q':qlist,\n",
    "           'from':date,\n",
    "           'sortBy':'popularity',\n",
    "            'pageSize':100,\n",
    "            'page':1,\n",
    "           'language':'en',\n",
    "           'apiKey':'697e87dceab84ce18c49963b7da44ac3'})\n",
    "        filename = './data/newscrape'+date+str(i)+'.csv'\n",
    "        if 'articles' in req.json().keys():\n",
    "            pd.DataFrame(req.json(),index=range(len(req.json()['articles']))).to_csv(filename)\n",
    "        if req.json()['totalResults']<100:\n",
    "            n_articles+=req.json()['totalResults']\n",
    "        elif req.json()['totalResults']>=100:\n",
    "            n_articles+=100\n",
    "    preq= requests.get(\n",
    "    base_url,\n",
    "    params={'q':president,\n",
    "       'from':date,\n",
    "       'sortBy':'popularity',\n",
    "        'pageSize':100,\n",
    "        'page':1,\n",
    "        'language':'en',\n",
    "       'apiKey':'697e87dceab84ce18c49963b7da44ac3'})\n",
    "    filename = './data/newscrape'+date+'trump'+'.csv'\n",
    "    if 'articles' in preq.json().keys():\n",
    "        pd.DataFrame(preq.json(),index=range(len(preq.json()['articles']))).to_csv(filename)\n",
    "    if req.json()['totalResults']<100:\n",
    "        n_articles+=req.json()['totalResults']\n",
    "    elif req.json()['totalResults']>=100:\n",
    "        n_articles+=100\n",
    "    print(n_articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(17,19):\n",
    "    date = '2019-08-'+str(i).zfill(2)\n",
    "    get_news(date,politicians)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dsi]",
   "language": "python",
   "name": "conda-env-dsi-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
